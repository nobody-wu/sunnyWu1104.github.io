<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[【Docker安装】Linux内核版本影响Docker启动]]></title>
    <url>%2F2018%2F06%2F28%2Fdocker-version-install%2F</url>
    <content type="text"><![CDATA[问题：今天想玩一个开源的应用，顺便想在一台服务器(Ubuntu16.04)上安装Docker(之前在虚拟机上玩的)，加载开源应用的镜像。但是发现Docker启动报错： 1Job for docker.service failed because the control process exited with error code 使用systemctl status docker.service 查看具体的错误信息: 解决看了网上很多资料都不行，接着排查是否是系统发型版本不对导致错误。官网上支持的发行版本如下： 12345Docker CE 支持以下版本的 Ubuntu 操作系统：Artful 17.10 (Docker CE 17.11 Edge +)Xenial 16.04 (LTS)Trusty 14.04 (LTS) 123456Docker CE 支持以下版本的 Debian 操作系统：Buster 10 (Docker CE 17.11 Edge +)Stretch 9Jessie 8 (LTS)Wheezy 7.7 (LTS) 12Docker CE 支持 64 位版本 CentOS 7，并且要求内核版本不低于 3.10。CentOS 7 满足最低内核的要求，但由于内核版本比较低，部分功能（如 overlay2 存储层驱动）无法使用，并且部分功能可能不太稳定。 发现发行版本没有问题，但是CentOS强调Linux内核版本，所以去看了服务器上的内核版本，发现服务器上的版本为：2.6+ 虽然官网没有强调ubuntu也有内核版本的影响，但是我想原因就是出在这！不然我之前在虚拟机上也不会安装成功了。 总结之后看服务器，除了发行版本，也要注意内核版本的不同。 ps这里有两种解决办法，可以进行参考(没有验证过)： 解决Docker启动服务器链接失败-Job for docker.service failed because the control process exited error code docker安装升级linux内核(2.6.32-&gt;3.10.81)，安装成功！]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【github】为了让自己变得更绿]]></title>
    <url>%2F2018%2F06%2F28%2Fgithub-green-command%2F</url>
    <content type="text"><![CDATA[问题作为一个程序员，看着自己”绿油油”的github提交记录，一定是一件令人高兴的事。 然而，用了这么久的github，我今天才注意到，我之前的所有commit都没有被”绿”，只有一些创建项目时的记录，这让我很奇怪。不过github用户记录一定是与邮箱相绑定的。 于是，我查看了一下commit的详细记录: 好吧，原来是我在公司的电脑上使用的gitconfig绑定的是公司邮箱，然而github上是自己的谷歌邮箱。 so，let’s fix this problem！ solution 全局修改 12345vim ~/.gitconfig 修改配置或者git config --global user.email you@example.com 局部修改 1git config user.email you@example.com 也可以修改提交的用户名和Email 1git commit --amend --email=&apos;you@example.com&apos; 总结git config是用于进行一些配置设置，有三种不同的方式来指定这些配置适用的范围： git config 针对一个git仓库 git config –global 针对一个用户 sudo git config –system 针对一个系统，因为是针对整个系统的，所以必须使用sudo]]></content>
      <categories>
        <category>git-command</category>
      </categories>
      <tags>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker三剑客之Swarm项目]]></title>
    <url>%2F2018%2F06%2F28%2Fdocker-swarm%2F</url>
    <content type="text"><![CDATA[Docker Machine让我们更便捷的添加处理主机，Docker Swarm让我们更加方便的管理主机 为什么存在Swarm项目Docker Swarm 是 Docker 官方三剑客项目之一，提供 Docker 容器集群服务，是 Docker 官方对容器云生态进行支持的核心方案。 使用它，用户可以将多个 Docker 主机封装为单个大型的虚拟 Docker 主机，快速打造一套容器云平台。 注意：Docker 1.12 Swarm mode 已经内嵌入 Docker 引擎，成为了 docker 子命令 docker swarm。请注意与旧的 Docker Swarm 区分开来。 Swarm mode 内置 kv 存储功能，提供了众多的新特性，比如：具有容错能力的去中心化设计、内置服务发现、负载均衡、路由网格、动态伸缩、滚动更新、安全传输等。使得 Docker 原生的 Swarm 集群具备与 Mesos、Kubernetes 竞争的实力。 Docker Swarm的基本概念Swarm 是使用 SwarmKit 构建的 Docker 引擎内置（原生）的集群管理和编排工具。 节点运行 Docker 的主机可以主动初始化一个 Swarm 集群或者加入一个已存在的 Swarm 集群，这样这个运行 Docker 的主机就成为一个 Swarm 集群的节点 (node) 。 节点分为管理 (manager) 节点和工作 (worker) 节点。 管理节点用于 Swarm 集群的管理，docker swarm 命令基本只能在管理节点执行（节点退出集群命令 docker swarm leave 可以在工作节点执行）。一个 Swarm 集群可以有多个管理节点，但只有一个管理节点可以成为 leader，leader 通过 raft 协议实现。 工作节点是任务执行节点，管理节点将服务 (service) 下发至工作节点执行。管理节点默认也作为工作节点。你也可以通过配置让服务只运行在管理节点。 服务和任务任务 （Task）是 Swarm 中的最小的调度单位，目前来说就是一个单一的容器。 服务 （Services） 是指一组任务的集合，服务定义了任务的属性。 服务有两种模式： replicated services 按照一定规则在各个工作节点上运行指定个数的任务。 global services 每个工作节点上运行一个任务 两种模式通过 docker service create 的 –mode 参数指定。 创建Swarm集群初始化集群使用 virtualbox 创建管理节点123docker-machine create --driver virtualbox manager1#进入管理节点docker-machine ssh manager1 执行 sudo -i 可以进入Root 权限 使用 docker swarm init 在 manager1 初始化一个 Swarm 集群 1docker@manager1:~$ docker swarm init --advertise-addr 192.168.99.100 如果你的 Docker 主机有多个网卡，拥有多个 IP，必须使用 –advertise-addr 指定 IP。 执行 docker swarm init 命令的节点自动成为管理节点。 命令 docker info 可以查看 swarm 集群状态: 1234567891011Containers: 0Running: 0Paused: 0Stopped: 0 ...snip...Swarm: active NodeID: dxn1zf6l61qsb1josjja83ngz Is Manager: true Managers: 1 Nodes: 1 ...snip... 命令 docker node ls 可以查看集群节点信息 1docker@manager1:~$ docker node ls 退出manager1虚拟主机 1docker@manager1:~$ exit 增加工作节点上一步初始化了一个 Swarm 集群，拥有了一个管理节点，在 Docker Machine 一节中我们了解到 Docker Machine 可以在数秒内创建一个虚拟的 Docker 主机，下面我们使用它来创建两个 Docker 主机，并加入到集群中。 创建虚拟主机 worker1 1docker-machine create -d virtualbox worker1 进入虚拟主机 worker1 1docker-machine ssh worker1 加入 swarm 集群 123docker@worker1:~$ docker swarm join \ --token SWMTKN-1-47z6jld2o465z30dl7pie2kqe4oyug4fxdtbgkfjqgybsy4esl-8r55lxhxs7ozfil45gedd5b8a \ 192.168.99.100:2377 退出虚拟主机 1docker@worker1:~$ exit 创建虚拟主机 worker2 步骤同上1～4 两个工作节点添加完成。 查看集群进入管理节点： 1docker-machine ssh manager1 宿主机子上查看虚拟主机: 1docker-machine ls 在主节点上面执行 docker node ls 查询集群主机信息: 1docker node ls 到此集群便创建成功了！ 部署服务使用 docker service 命令来管理 Swarm 集群中的服务，该命令只能在管理节点运行。 新建服务进入集群管理节点： 1docker-machine ssh manager1 使用 docker 中国镜像: 12docker search alpinedocker pull registry.docker-cn.com/library/alpine 在上一节创建的 Swarm 集群中运行一个名为 helloworld 服务: 123456docker service create --replicas 1 --name helloworld alpine ping baidu.comrwpw7eij4v6h6716jvqvpxbyvoverall progress: 1 out of 1 tasks1/1: running [==================================================&gt;]verify: Service converged 命令解释： docker service create 命令创建一个服务 –name 服务名称命名为 helloworld –replicas 设置启动的示例数 alpine 指的是使用的镜像名称，ping ityouknow.com指的是容器运行的bash 使用命令 docker service ps rwpw7eij4v6h6716jvqvpxbyv 可以查看服务进展 1234docker service ps rwpw7eij4v6h6716jvqvpxbyvID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTSrgroe3s9qa53 helloworld.1 alpine:latest worker1 Running Running about a minute ago 使用 docker service ls 来查看当前 Swarm 集群运行的服务: 123 docker service lsID NAME MODE REPLICAS IMAGE PORTSyzfmyggfky8c helloworld replicated 0/1 alpine:latest 监控集群状态登录管理节点 manager1: 1docker-machine ssh manager1 运行 docker service inspect –pretty 查询服务概要状态，以 helloworld 服务为例： 1234567891011121314151617181920运行 docker service inspect helloworld 查询服务详细信息docker service inspect --pretty helloworldID: rwpw7eij4v6h6716jvqvpxbyvName: helloworldService Mode: Replicated Replicas: 1Placement:UpdateConfig: Parallelism: 1 On failure: pause Monitoring Period: 5s Max failure ratio: 0 ... Rollback order: stop-firstContainerSpec: Image: alpine:latest@sha256:7b848083f93822dd21b0a2f14a110bd99f6efb4b838d499df6d04a49d0debf8b Args: ping ityouknow.comResources:Endpoint Mode: vip 运行docker service ps 查看那个节点正在运行服务: 1234docker service ps helloworldNAME IMAGE NODE DESIRED STATE LAST STATEhelloworld.1.8p1vev3fq5zm0mi8g0as41w35 alpine worker1 Running Running 3 minutes 在工作节点查看任务的执行情况: 1docker-machine ssh worker1 在节点执行docker ps 查看容器的运行状态: 1234docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES96bf5b1d8010 alpine:latest &quot;ping ityouknow.com&quot; 4 minutes ago Up 4 minutes 在 Swarm 集群中成功的运行了一个 helloworld 服务，根据命令可以看出在 worker1 节点上运行。 弹性伸缩实验可以使用 docker service scale 对一个服务运行的容器数量进行伸缩。 当业务处于高峰期时，我们需要扩展服务运行的容器数量: 12345docker service scale nginx=5等同于docker service update --replicas 5 helloworld 当业务平稳时，我们需要减少服务运行的容器数量: 12345docker service scale nginx=2等同于docker service update --replicas 2 helloworld 删除集群服务: 1docker service rm helloworld 调整集群大小: 123456789101. 创建虚拟主机 worker3 docker-machine create -d virtualbox worker32. 进入虚拟主机 worker3 docker-machine ssh worker33. 加入swarm 集群 docker swarm join \ --token SWMTKN-1-47z6jld2o465z30dl7pie2kqe4oyug4fxdtbgkfjqgybsy4esl-8r55lxhxs7ozfil45gedd5b8a \ 192.168.99.100:2377 这时进入manager主机查看node，看出集群节点多了 worker3。 退出 Swarm 集群: 进入对应的work主机后，执行: 1docker swarm leave 重新搭建命令 使用 VirtualBox 做测试的时候，如果想重复实验可以将实验节点删掉再重来。 123456789//停止虚拟机docker-machine stop [arg...] //一个或多个虚拟机名称docker-machine stop manager1 worker1 worker2//移除虚拟机docker-machine rm [OPTIONS] [arg...]docker-machine rm manager1 worker1 worker2 停止、删除虚拟主机后，再重新创建即可。 在 Swarm 集群中使用 compose 文件之前使用 docker-compose.yml 来一次配置、启动多个容器，在 Swarm 集群中也可以使用 compose 文件 （docker-compose.yml） 来配置、启动多个服务。 以在 Swarm 集群中部署 WordPress 为例进行说明: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647version: &quot;3&quot;services: wordpress: image: wordpress ports: - 80:80 networks: - overlay environment: WORDPRESS_DB_HOST: db:3306 WORDPRESS_DB_USER: wordpress WORDPRESS_DB_PASSWORD: wordpress deploy: mode: replicated replicas: 3 db: image: mysql networks: - overlay volumes: - db-data:/var/lib/mysql environment: MYSQL_ROOT_PASSWORD: somewordpress MYSQL_DATABASE: wordpress MYSQL_USER: wordpress MYSQL_PASSWORD: wordpress deploy: placement: constraints: [node.role == manager] visualizer: image: dockersamples/visualizer:stable ports: - &quot;8080:8080&quot; stop_grace_period: 1m30s volumes: - &quot;/var/run/docker.sock:/var/run/docker.sock&quot; deploy: placement: constraints: [node.role == manager]volumes: db-data:networks: overlay: 部署compose部署服务使用 docker stack deploy，其中 -c 参数指定 compose 文件名。 1docker stack deploy -c docker-compose.yml wordpress 打开浏览器输入 任一节点IP:8080 即可看到各节点运行状态。如下图所示： 查看服务1234docker stack lsNAME SERVICESwordpress 3 移除服务1docker stack down wordpress 在 Swarm 集群管理节点新建该文件，其中的 visualizer 服务提供一个可视化页面，我们可以从浏览器中很直观的查看集群中各个服务的运行节点。 在 Swarm 集群中使用 docker-compose.yml 我们用 docker stack 命令，下面我们对该命令进行详细讲解。 在 Swarm 集群中管理敏感数据在动态的、大规模的分布式集群上，管理和分发 密码、证书 等敏感信息是极其重要的工作。传统的密钥分发方式（如密钥放入镜像中，设置环境变量，volume 动态挂载等）都存在着潜在的巨大的安全风险。 Docker 目前已经提供了 secrets 管理功能，用户可以在 Swarm 集群中安全地管理密码、密钥证书等敏感数据，并允许在多个 Docker 容器实例之间共享访问指定的敏感数据。 注意： secret 也可以在 Docker Compose 中使用。 创建 secret 创建文件 password.txt，里面存入 Mysql 的 root 密码 创建文件 wordpress.yml，用于启动 mysql 和 wordpress 服务，内容： 123456789101112131415161718192021222324252627version: &apos;3.3&apos;services: db: image: mysql:latest environment: MYSQL_ROOT_PASSWORD_FILE: /run/secrets/db_password MYSQL_DATABASE: wordpress secrets: - db_password wordpress: depends_on: - db image: wordpress:latest ports: - &quot;8000:80&quot; environment: WORDPRESS_DB_HOST: db:3306 WORDPRESS_DB_USER: root WORDPRESS_DB_PASSWORD_FILE: /run/secrets/db_password secrets: - db_passwordsecrets: db_password: file: password.txt 启动 wordpress 服务: 1docker stack deploy -c wordpress.yml wordpress 除了在Docker Componse里使用，也可以使用 docker secret create 命令以管道符的形式创建 secret 123$ openssl rand -base64 20 | docker secret create mysql_password -$ openssl rand -base64 20 | docker secret create mysql_root_password - 创建 MySQL 服务: 1234567891011121314$ docker network create -d overlay mysql_private$ docker service create \ --name mysql \ --replicas 1 \ --network mysql_private \ --mount type=volume,source=mydata,destination=/var/lib/mysql \ --secret source=mysql_root_password,target=mysql_root_password \ --secret source=mysql_password,target=mysql_password \ -e MYSQL_ROOT_PASSWORD_FILE=&quot;/run/secrets/mysql_root_password&quot; \ -e MYSQL_PASSWORD_FILE=&quot;/run/secrets/mysql_password&quot; \ -e MYSQL_USER=&quot;wordpress&quot; \ -e MYSQL_DATABASE=&quot;wordpress&quot; \ mysql:latest 如果没有在 target 中显式的指定路径时，secret 默认通过 tmpfs 文件系统挂载到容器的 /run/secrets 目录中。 123456789101112docker service create \ --name wordpress \ --replicas 1 \ --network mysql_private \ --publish target=30000,port=80 \ --mount type=volume,source=wpdata,destination=/var/www/html \ --secret source=mysql_password,target=wp_db_password,mode=0400 \ -e WORDPRESS_DB_USER=&quot;wordpress&quot; \ -e WORDPRESS_DB_PASSWORD_FILE=&quot;/run/secrets/wp_db_password&quot; \ -e WORDPRESS_DB_HOST=&quot;mysql:3306&quot; \ -e WORDPRESS_DB_NAME=&quot;wordpress&quot; \ wordpress:latest 通过以上方法，没有像以前通过设置环境变量来设置 MySQL 密码， 而是采用 docker secret 来设置密码，防范了密码泄露的风险。 总结在公司流量爆发的时候，只需要执行一个命令就可以完成实例上线。如果再根据公司的业务流量做自动化控制，那就真正实现了完全自动的动态伸缩。]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[项目平滑部署]]></title>
    <url>%2F2018%2F06%2F28%2Fdeploy-strategy%2F</url>
    <content type="text"><![CDATA[这周需要出一个技术方案，有关于项目部署时尽可能地平滑处理。由此做一下小记，下一篇会对6中部署策略做解释 引言单机服务器我们会面临很多生产上的问题： 怕服务器压力过大，任务处理缓慢 内存不足，服务挂了 项目发布导致服务停机 … 考虑到负载均衡，一般的项目都会使用2台以上的服务器。这次我们主要分享项目发布部署的问题。 单机发布在单机情况下，基本上也不需要考虑太多了。。直接kill后，重启容器进行部署。这也是部署策略中的重建策略。这个方式意味着服务的宕机时间依赖于应用下线和启动耗时。 多机灰度发布方案一最容易理解的方式，我们可以通过Nginx做负载均衡，达到较为”平滑”的发布。这种方式优点就是操作比较简单，缺点是影响用户操作。如果某个用户的操作刚好落在正在发布重启的 tomcat 节点上，必然会受到影响，虽然是短暂的。而在其他 tomcat 继续发布的时候，又会扩大这种影响。其实整个过程就是部署策略中的—蓝绿部署。 一般我们生产环境下，会有两组 tomcat ， 一组用于线上服务（线上组），一组作为备份（备份组）。我们可以先将备份组所有 tomcat 节点部署好，然后修改 nginx 配置文件，切换到备份组，然后操作 nginx 平滑 reload 配置文件。最后再将 线上组 所有 tomcat 节点部署好。 此时 备份组转为线上组，而线上组转为备份组。 方案二通过Nginx反向代理，达到测试人员使用线上环境针对新的应用进行测试，然而正常用户还是使用原来的应用。整个过程有点像A/B部署策略 可以根据公网ip进行反向代理，本部门的公网ip是固定的，那么当客户访问的时候，如果是本部门的公网ip的话，nginx进行方向代理到新代码tomcat上，如果非本部门的公网ip，那么代理到原有tomcat上。 !(nginx)[http://p95stksgt.bkt.clouddn.com/deploy-nginx.png] 参考Nginx代码： 1234567891011121314151617181920212223242526272829303132upstream jljerp &#123; server 192.168.1.190:8001 weight=20 max_fails=2 fail_timeout=30s; ip_hash; &#125;upstream jljerp_rc &#123; server 192.168.1.190:8004 weight=20 max_fails=2 fail_timeout=30s; ip_hash; &#125;server &#123; listen 80; server_name jljerp.jinlejia.com; root /var/www/index; index index.html index.htm;location / &#123; proxy_set_header HOST $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-FOR $proxy_add_x_forwarded_for; proxy_connect_timeout 600; proxy_read_timeout 600; proxy_send_timeout 600; # 预发布规则，这个地址是部门内部公网地址，当这个地址过来的请求转发到新tomcat上 if ($remote_addr ~* &quot;202.106.0.20&quot;) &#123; proxy_pass http://jljerp_rc; &#125; # 如果不是本部门ip请求，按照原有规则进行原有生产环境进行转发 proxy_pass http://jljerp; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root /usr/share/nginx/html; &#125;&#125; 静态规则： 123456789101112131415161718192021222324server &#123; listen 80; server_name www.a.com; root /var/www/a; index index.html index.htm; location / &#123; # 预发布规则,如果是本部门的公网的ip，访问这个目录下的地址 if ($remote_addr ~* &quot;202.106.0.20&quot;)&#123; root /var/www/b; &#125; &#125;# 由于字体使用跨域的方式进行的调用，默认浏览器拒绝访问，加上这个location就可以在其他域名下访问这个域名的字体了 location ~* \.(eot|ttf|woff|svg|otf|woff2)$ &#123; add_header Access-Control-Allow-Origin *; &#125; error_page 404 500 502 503 504 /404.html; location = /404.html &#123; root /usr/share/nginx/html; &#125;&#125;]]></content>
      <categories>
        <category>deploy</category>
      </categories>
      <tags>
        <tag>deploy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【SS/SSR】GFW与SS/SSR]]></title>
    <url>%2F2018%2F06%2F28%2FGFW-SS%26SSR%2F</url>
    <content type="text"><![CDATA[Phase 1:起初,我们对网络的访问时非常直接的,我们(客户端)向对方(服务端)发出请求,对方回应请求. Phase 2:后来,建立了GFW(Great FireWall),也就是伟大的中国国家防火墙. 下面花一点篇幅说几个GFW的封锁原理. 1.域名解析服务缓存污染首先,GFW使用了返回错误的DNS查询结果的方式,比如,当长城监听它骨干出口上某端口的DNS查询(当然这是UDP),接着对其进行入侵检测,一旦发现了和黑名单上关键词相匹配的域名查询请求,就会马上开始当演员,返回一个虚假的结果,这样,我们就会遭遇连接重置，无法获得目标网站的IP地址。 2.针对境外的IP地址封锁防火长城的路由扩散技术中使用的静态路由其实是一条错误的路由，而且是有意配置错误的，其目的就是为了把本来是发往某个IP地址的数据包统统引导到一个“黑洞服务器”上，这个黑洞服务器上可以什么也不做，这样数据包就被无声无息地丢掉了,当然也可以进行一个虚假的回复.接着通过路由重分发,整个网络被打通,大家就都知道这样的IP要发向这么一个黑洞了,效率也得到了提升(封IP封的越来越开心了呢) 3.IP地址特定端口封锁结合2,为了达到更精确的封锁,长城会对特定端口上的数据包进行全部丢弃,以达到更彻底的封锁. 常常封锁的端口: 1234567SSH TCP 22HTTP 80(PPTP)VPN TCP 1723(L2TP)VPN UDP 1701IPSec/L2TP UDP 500&amp;4500OpenVPN TCP/UDP 1194TLS/SSL/HTTPS TCP 443 另外,中国X动,中国X通等ISP的手机IP端,所有的PPTP都被封锁. 4.对加密连接的干扰(不太了解加密握手可以看看隔壁的TLS/SSL)在连接握手时，因为服务器的公钥是明文传输的，长城会阻断特定证书的加密连接，方法和无状态TCP连接重置一样，都是先发现匹配的黑名单证书，之后通过伪装成对方向连接两端的计算机发送RST干扰两者间正常的TCP连接，进而打断与特定IP地址之间的TLS加密连接握手，或者干脆直接将握手的数据包丢弃导致握手失败，从而导致TLS连接失败. 5.深度包检测深度数据包检测(Deep Package Inspection)是一种于应用层对网络上传递的数据进行侦测与处理的技术，DPI可对报文内容和协议特征进行检测。(似乎这个就是所谓的流量审查) 在中国大陆，DPI一度被ISP用于追踪用户行为以改善其广告推送业务的精准性，长城赖以检测关键词及嗅探加密流量的重要技术之一.基于必要的硬件设施、适宜的检测模型及相应的模式匹配算法，长城能够精确且快速地从实时网络环境中判别出有悖于预期标准的可疑流量，并对此及时作出相应地应对措施. Phase 3: 针对一些封锁技术,勤劳智慧而又充满勇气的天朝人民,使用了境外HTTP服务器代理,SOCKS服务,VPN 等等各种方式来 Break the GFW. 然而,尽管SSH是安全的,长城并不能知道里面发生了什么样的数据交换,它却依旧能在建立隧道时,分析连接特征从而进行干扰或是重定向连接. 其他的几种方式,也都差不多. Phase 4: 于是,出现了cloudwindy同学…带来的SS,没错,他被警察请去喝茶了. 延续Phase3,ShadowSocks实际上是将 SSH 创建的SOCKS5协议 拆成两个部分,server 端和 client 端 不同的地方在于,客户端发出的请求基于 Socks5 协议跟 ss-local 端进行通讯，由于这个 ss-local 一般是本机或路由器或局域网的其他机器，不经过 GFW，所以解决了上面被 GFW 通过特征分析进行干扰的问题.那么,就总体来说一下SS的运作流程: 首先,在服务器上配置好了 SS 服务器后,用户按照指定的密码、加密方式和端口使用 SS 客户端与其连接。在成功连接到服务器后，客户端会在用户的电脑上构建一个本地Socks5 代理。浏览网络时，网络流量会被分到本地socks5 代理，客户端将其加密之后发送到服务器，服务器以同样的加密方式将流量回传给客户端，以此实现代理上网。 Phase 5:后来,似乎GFW对SS的流量有了某种辨识能力,于是,Github上一位叫BreakWa11的作者修改了原SS的代码,增加了混淆以及其他的一些功能(这里面有场不小的风波,从中可以学到一些开源协议的知识…感兴趣的去搜搜看),名为SSR. 其中使用的混淆机制有: http_simple tls_simple random_head tls1.0_session_auth 说说这其中比较好理解的 tls1.0_session_auth:模拟TLS1.0在客户端有session ID的情况下的握手连接。因为有session ID所以没有发送证书等复杂步骤，因而防火墙无法根据证书做判断(之前说过),同时自带一定的抗重放攻击的能力。 由于防火墙对TLS比较无能为力，抗封锁能力较强 random_head：开始通讯前发送一个几乎为随机的数据包,之后为原协议流。目标是让首个数据包根本不存在任何有效信息,使得GFW的统计学习机制失效. 传送门:转自【传送门】 Post author: Justin13Post link: https://justin13wyx.me/2017/04/13/SS-SSR/]]></content>
      <categories>
        <category>兴趣</category>
      </categories>
      <tags>
        <tag>SS/SSR</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker三剑客之Machine项目]]></title>
    <url>%2F2018%2F06%2F28%2Fdocker-machine%2F</url>
    <content type="text"><![CDATA[Docker Componse吸引我学习Docker，Machine令我爱上Docker，一定不要错过这两个伟大的项目。严肃脸:) Docker Machine 介绍Docker Machine 是 Docker 官方编排（Orchestration）项目之一，负责在多种平台上快速安装 Docker 环境。 Docker Machine 是一个工具，它允许你在虚拟宿主机上安装 Docker Engine ，并使用 docker-machine 命令管理这些宿主机。你可以使用 Machine 在你本地的 Mac 或 Windows box、公司网络、数据中心、或像 AWS 或 Digital Ocean 这样的云提供商上创建 Docker 宿主机。（跨平台，跨环境） 使用 docker-machine 命令，你可以启动、审查、停止和重新启动托管的宿主机、升级 Docker 客户端和守护程序、并配置 Docker 客户端与你的宿主机通信。（集中管理） Docker Machine 项目基于 Go 语言实现（习惯面向对象的同学，学习go的基础语法，不超过一周），目前在 Github 上进行维护。 为什么要使用它？ 跨平台跨环境运行Docker Machine 允许你在较早的 Mac 或 Windows 系统上运行 Docker 如果你主要在不符合新的 Docker for Mac 和 Docker for Windows 应用程序的旧 Mac 或 Windows 笔记本电脑或台式机上工作，则需要 Docker Machine 来在本地“运行Docker”（即Docker Engine）。在 Mac 或 Windows box 中使用 Docker Toolbox 安装程序安装 Docker Machine 将为 Docker Engine 配置一个本地的虚拟机，使你能够连接它、并运行 docker 命令。 远程系统集中配置Docker宿主机 Docker Engine Linux 系统上原生地运行。如果你有一个 Linux 作为你的主系统，并且想要运行 docker 命令，所有你需要做的就是下载并安装 Docker Engine 。然而，如果你想要在网络上、云中甚至本地配置多个 Docker 宿主机有一个有效的方式，你需要 Docker Machine。 无论你的主系统是 Mac、Windows 还是 Linux，你都可以在其上安装 Docker Machine，并使用 docker-machine 命令来配置和管理大量的 Docker 宿主机。它会自动创建宿主机、在其上安装 Docker Engine 、然后配置 docker 客户端。每个被管理的宿主机（“machine”）是 Docker 宿主机和配置好的客户端的结合。 Docker Engine 和 Docker Machine 有什么区别？首先，Docker Engine与Docker Machine都有自己的命令行客户端。但是Docker Machine 是一个用于配置和管理你的宿主机（上面具有 Docker Engine 的主机）的工具，可以使用Docker Machine在一个或多个虚拟系统上安装Docker Engine。 这些虚拟系统可以是本地的（就像你在 Mac 或 Windows 上使用 Machine 在 VirtualBox 中安装和运行 Docker Engine 一样）或远程的（就像你使用 Machine 在云提供商上 provision Dockerized 宿主机一样）。Dockerized 宿主机本身可以认为是，且有时就称为，被管理的“machines”。 eg: 本地系统安装Docker Machine 利用Docker Machine创建虚拟机 在虚拟机上就可以玩耍运行 Docker Engine 安装Docker Machinedocker-machine-release On Linux:123$ curl -L https://github.com/docker/machine/releases/download/v0.14.0/docker-machine-`uname -s`-`uname -m` &gt;/tmp/docker-machine &amp;&amp; chmod +x /tmp/docker-machine &amp;&amp; sudo cp /tmp/docker-machine /usr/local/bin/docker-machine On OS X:12$ curl -L https://github.com/docker/machine/releases/download/v0.14.0/docker-machine-`uname -s`-`uname -m` &gt;/usr/local/bin/docker-machine &amp;&amp; \ chmod +x /usr/local/bin/docker-machine On Windows with git bash:123$ if [[ ! -d &quot;$HOME/bin&quot; ]]; then mkdir -p &quot;$HOME/bin&quot;; fi &amp;&amp; \curl -L https://github.com/docker/machine/releases/download/v0.14.0/docker-machine-Windows-x86_64.exe &gt; &quot;$HOME/bin/docker-machine.exe&quot; &amp;&amp; \chmod +x &quot;$HOME/bin/docker-machine.exe&quot; 使用Docker MachineDocker Machine 支持多种后端驱动，包括虚拟机、本地主机和云平台等。 创建本地主机实例:Virtualbox 驱动Linux 17.10安装VirtualBox这里演示的是一个通过Docker Machine创建一个VirtualBox，但是想要创建VirtualBox，首先需要当前主机已经安装了virtualbox才可以继续。 如果你使用Mac OS/Windows，那么很幸运，你只需要去VirtualBox的官网下载对应的包即可。如果使用的是Linux操作系统，那么会很麻烦。我这边展示一下使用Linux如果安装VirtualBox（毕竟，方便的事做了也没意思:)） 我的操作系统版本：Linux 17.10 Setup Apt Repository 打开/etc/apt/source.list文件，添加以下代码: 1234567891011121314151617181920For Ubuntu 17.10 (&quot;artful&quot;)deb http://download.virtualbox.org/virtualbox/debian artful contribFor Ubuntu 17.04 (&quot;Zesty&quot;)deb http://download.virtualbox.org/virtualbox/debian zesty contribFor Ubuntu 16.04 (&quot;Xenial&quot;)deb http://download.virtualbox.org/virtualbox/debian xenial contribFor Ubuntu 14.04 (&quot;Trusty&quot;)deb http://download.virtualbox.org/virtualbox/debian trusty contribFor Ubuntu 12.04 LTS (&quot;Precise Pangolin&quot;)deb http://download.virtualbox.org/virtualbox/debian precise contribFor Debian 8 (&quot;Jessie&quot;)deb http://download.virtualbox.org/virtualbox/debian jessie contribFor Debian 7 (&quot;Wheezy&quot;)deb http://download.virtualbox.org/virtualbox/debian wheezy contrib 不知道名称的，出门左转virtualbox Setup Oracle public key 添加公钥使其信任 12$ curl -fsS https://www.virtualbox.org/download/oracle_vbox_2016.asc -O- | sudo apt-key add -$ curl -fsS https://www.virtualbox.org/download/oracle_vbox.asc -O- | sudo apt-key add - 这一步和安装Docker时添加官方GPG密钥一致 Install Oracle VirtualBox 愉快的安装 12sudo apt-get updatesudo apt-get install virtualbox-5.1 创建一个虚拟机安装完VirtualBox后，继续创建虚拟主机 使用 virtualbox 类型的驱动，创建一台 Docker 主机，命名为 default。 1docker-machine create --driver virtualbox default 也可以在创建时加上如下参数，来配置主机或者主机上的 Docker: –engine-opt dns=114.114.114.114 配置 Docker 的默认 DNS –engine-registry-mirror https://registry.docker-cn.com 配置 Docker 的仓库镜像 –virtualbox-memory 2048 配置主机内存 –virtualbox-cpu-count 2 配置主机 CPU ps: 前一天刚实验完，可以创建在虚拟机内安装并虚拟机，但是今天却再次创建虚拟机的时候就报错: 1This computer doesn&apos;t have VT-X/AMD-v enabled. Enabling it in the BIOS is mandatory 这表示系统没有开启Intel Virtualization Technology，可是我偏偏该死的用的Virtualbox，这个虚拟机只有EFI(虽然类似bios，但是少了很多选项)并没有bios，试着半天没有办法继续下去。（命令行直接修改没有试过行不行，应该是不行的） 后来google告诉我虚拟机内是不支持虚拟机的虚拟化。。。要这么说的话，云服务器&amp;云主机&amp;虚拟主机通过虚拟化手段的主机都不能用了。难道我昨天活在梦里了？？？ 这里就不再继续演示virtualbox的驱动了，大家可以找别的玩玩 • amazonec2 • azure • digitalocean • exoscale • generic • google • hyperv • none • openstack • rackspace • softlayer • virtualbox • vmwarevcloudair • vmwarefusion • vmwarevsphere 创建本地主机实例:macOS xhyve 驱动xhyve 驱动 xhyve 是 macOS 上轻量化的虚拟引擎，使用其创建的 Docker Machine 较 VirtualBox 驱动创建的运行效率要高。 表示没用过，做下记录。有需要的同学可以尝试一下。 1234567891011$ brew install docker-machine-driver-xhyve$ docker-machine create \ -d xhyve \ # --xhyve-boot2docker-url ~/.docker/machine/cache/boot2docker.iso \ --engine-opt dns=114.114.114.114 \ --engine-registry-mirror https://registry.docker-cn.com \ --xhyve-memory-size 2048 \ --xhyve-rawdisk \ --xhyve-cpu-count 2 \ xhyve 注意：非首次创建时建议加上 –xhyve-boot2docker-url ~/.docker/machine/cache/boot2docker.iso 参数，避免每次创建时都从 GitHub 下载 ISO 镜像。 创建本地主机实例:Windows 10Windows 10 安装 Docker for Windows 之后不能再安装 VirtualBox，也就不能使用 virtualbox 驱动来创建 Docker Machine，我们可以选择使用 hyperv 驱动。 注意，必须事先在 Hyper-V 管理器中新建一个 外部虚拟交换机 执行下面的命令时，使用 –hyperv-virtual-switch=MY_SWITCH 指定虚拟交换机名称 1docker-machine create --driver hyperv --hyperv-virtual-switch=MY_SWITCH vm 创建一个主机1docker-machine create --driver virtualbox default 这个命令会下载 boot2docker，基于 boot2docker 创建一个虚拟主机。boot2docker 是一个轻量级的 linux 发行版，基于专门为运行 docker 容器而设计的 Tiny Core Linux 系统，完全从 RAM 运行，45Mb左右，启动时间约5s。 服务列表: 1docker-machine ls 创建主机成功后，可以通过 env 命令来让后续操作对象都是目标主机。 1docker-machine env [主机名] 可以通过 SSH 登录到主机: 1docker-machine ssh [主机名] 连接到主机之后你就可以在其上使用 Docker 了，退出虚拟机使用命令：exit 在远程主机上安装 Docker前提条件：ssh证书登录已打通 12345$ docker-machine create -d generic \ --generic-ip-address=xxx.xxx.xxx.xxx \ --generic-ssh-user=nick \ --generic-ssh-key ~/.ssh/id_rsa \ krdevdb Docker Machine 常用命令//创建虚拟机docker-machine create [OPTIONS] [arg…] //移除虚拟机docker-machine rm [OPTIONS] [arg…] //登录虚拟机docker-machine ssh [arg…] //docker客户端配置环境变量docker-machine env [OPTIONS] [arg…] //检查机子信息docker-machine inspect //查看虚拟机列表docker-machine ls [OPTIONS] [arg…] //查看虚拟机状态docker-machine status [arg…] //一个虚拟机名称 //启动虚拟机docker-machine start [arg…] //一个或多个虚拟机名称 //停止虚拟机docker-machine stop [arg…] //一个或多个虚拟机名称 //重启虚拟机docker-machine restart [arg…] //一个或多个虚拟机名称 更多命令• active 查看活跃的 Docker 主机 • config 输出连接的配置信息 • create 创建一个 Docker 主机 • env 显示连接到某个主机需要的环境变量 • inspect 输出主机更多信息 • ip 获取主机地址 • kill 停止某个主机 • ls 列出所有管理的主机 • provision 重新设置一个已存在的主机 • regenerate-certs 为某个主机重新生成 TLS 认证信息 • restart 重启主机 • rm 删除某台主机 • ssh SSH 到主机上执行命令 • scp 在主机之间复制文件 • mount 挂载主机目录到本地 • start 启动一个主机 • status 查看主机状态 • stop 停止一个主机 • upgrade 更新主机 Docker 版本为最新 • url 获取主机的 URL • version 输出 docker-machine 版本信息 • help 输出帮助信息 每个命令，又带有不同的参数，可以通过 1$ docker-machine COMMAND --help 来查看具体的用法。]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Nginx】root和alias指令区别小记]]></title>
    <url>%2F2018%2F06%2F28%2Fnginx-command%2F</url>
    <content type="text"><![CDATA[问题：今天在搭建前端react项目的时候，nginx部署遇到了一个小问题:当前项目下引用的一些静态资源没有加载到，一直报错404，导致样式展示不全。 排查问题： 一直在怀疑是代码中引用的相对路径的问题，修改后问题还是无法修复。 怀疑nginx容器需要重启，问题还是无法修复。 排查nginx配置文件信息，发现了一些端倪： 原配置文件数据:1234567891011121314151617181920server &#123; listen 8800; server_name lcoalhost; access_log /data/www/logs/nginx/nginx_access.log local; location / &#123; root /data/www/static; index index.html;# try_files $uri $uri/index.html; &#125; error_page 405 =200 $uri; location /cashwallet &#123; alias /data/www/static; index index.html; try_files $uri /shaxiaoseng/index.html; &#125; 熟悉nginx的同学，估计在这里一眼就能发现问题了，不过我这边就直接贴出来修改后的配置文件 修改后的配置文件:123456789101112131415server &#123; listen 8888; server_name lcoalhost; access_log /data/www/logs/nginx/nginx_access.log local; location /cashwallet &#123; root /data/www/static; index index.html; try_files $uri /shaxiaoseng/index.html;# try_files $uri $uri/index.html; &#125; error_page 405 =200 $uri; 在这里我们可以发现一些改变：我将location下的alias修改为了root 原因:alias指令对于root，操作上很简单，只要把root地址替换host后就是文件在硬盘路径（真实地址）。对于alise，它并不是替换匹配后的url地址，而是替换匹配部分的url。alias指令也可以有多个 eg:使用root指令，查询的资源路径会是: /cashwallet/data/www/static/cashwallet 使用alias指令，查询的资源路径会是: /data/www/static/cashwallet 所以会导致查无资源的问题。 传送门:愿意的朋友，可以去【传送门】看这篇更为详细的介绍对比]]></content>
      <categories>
        <category>nginx日常小记</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker三剑客之Componse项目]]></title>
    <url>%2F2018%2F06%2F12%2Fdocker-componse%2F</url>
    <content type="text"><![CDATA[Docker Compose 是 Docker 官方编排（Orchestration）项目之一，负责快速的部署分布式应用。本章将介绍 Compose 项目情况以及安装和使用。 Dockerfile 可以让用户管理一个单独的应用容器；而 Compose 则允许用户在一个模板（YAML 格式）中定义一组相关联的应用容器（被称为一个 project，即项目），例如一个 Web 服务容器再加上后端的数据库服务容器等。 通过 Docker-Compose 用户可以很容易地用一个配置文件定义一个多容器的应用，然后使用一条指令安装这个应用的所有依赖，完成构建。Docker-Compose 解决了容器与容器之间如何管理编排的问题。 Compose 中有两个重要的概念： 服务 (service) ：一个应用的容器，实际上可以包括若干运行相同镜像的容器实例。 项目 (project) ：由一组关联的应用容器组成的一个完整业务单元，在 docker-compose.yml 文件中定义。一个项目可以由多个服务（容器）关联而成，Compose 面向项目进行管理，通过子命令对项目中的一组容器进行便捷地生命周期管理。Compose 项目由 Python 编写，实现上调用了 Docker 服务提供的 API 来对容器进行管理。因此，只要所操作的平台支持 Docker API，就可以在其上利用 Compose 来进行编排管理。 Docker一开始吸引我的点正是：Docker Componse(至少在没看到machine之前我是这么想的=。=、)，我觉得它完美的解决了服务器上一些服务的复杂部署。尤其是mysql、tomcat、nginx等等。Docker Componse就像哆啦A梦的神奇口袋（当然，官方镜像有时候并不能满足我们的需求，那就自己搞呗手动滑稽） 一张图了解一下原理： Docker Componse安装12345678910111213141516方法一：下载sudo curl -L https://github.com/docker/compose/releases/download/1.20.0/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose安装chmod +x /usr/local/bin/docker-compose方法二：#安装pipyum -y install epel-releaseyum -y install python-pip确认版本pip --version更新pippip install --upgrade pip安装docker-composepip install docker-compose 安装补全工具(可选)为了方便我们输入命令，也可以安装 Docker 的补全提示工具帮忙我们快速输入命令 12345#安装yum install bash-completion#下载docker-compose脚本curl -L https://raw.githubusercontent.com/docker/compose/$(docker-compose version --short)/contrib/completion/bash/docker-compose &gt; /etc/bash_completion.d/docker-compose Docker Compose 常用命令命令的基本的使用格式是: 12345678docker-compose [-f=&lt;arg&gt;...] [options] [COMMAND] [ARGS...] - -f, --file FILE 指定使用的 Compose 模板文件，默认为 docker-compose.yml，可以多次指定。 - -p, --project-name NAME 指定项目名称，默认将使用所在目录名称作为项目名。 - --x-networking 使用 Docker 的可拔插网络后端特性 - --x-network-driver DRIVER 指定网络后端的驱动，默认为 bridge - --verbose 输出更多调试信息。 - -v, --version 打印版本并退出。 build构建（重新构建）项目中的服务容器 格式为 docker-compose build [options] [SERVICE…] 选项包括： - --force-rm 删除构建过程中的临时容器。 - --no-cache 构建镜像过程中不使用 cache（这将加长构建过程）。 - --pull 始终尝试通过 pull 来获取更新版本的镜像。 config验证 Compose 文件格式是否正确，若正确则显示配置，若格式错误显示错误原因。 格式为 docker-compose config down此命令将会停止 up 命令所启动的容器，并移除网络 格式为 docker-compose down exec进入指定的容器。 格式为 docker-compose exec images列出 Compose 文件中包含的镜像。 格式为 docker-compose images kill通过发送 SIGKILL 信号来强制停止服务容器。支持通过 -s 参数来指定发送的信号，例如通过如下指令发送 SIGINT 信号。 格式为 docker-compose kill [options] [SERVICE…] logs查看服务容器的输出。默认情况下，docker-compose 将对不同的服务输出使用不同的颜色来区分。可以通过 –no-color 来关闭颜色。该命令在调试问题的时候十分有用。 格式为 docker-compose logs [options] [SERVICE…] pause暂停一个服务容器 格式为 docker-compose pause port打印某个容器端口所映射的公共端口 格式为 docker-compose port [options] SERVICE PRIVATE_PORT 选项： - --protocol=proto 指定端口协议，tcp（默认值）或者 udp。 - --index=index 如果同一服务存在多个容器，指定命令对象容器的序号（默认为 1）。 ps列出项目中目前的所有容器 格式为 docker-compose ps 选项： - -q 只打印容器的 ID 信息。 pull拉取服务依赖的镜像 格式为 docker-compose pull [options] [SERVICE…] 选项： - --ignore-pull-failures 忽略拉取镜像过程中的错误。 push推送服务依赖的镜像到 Docker 镜像仓库 格式为 docker-compose push restart重启项目中的服务 格式为 docker-compose restart [options] [SERVICE…] 选项： - -t, --timeout TIMEOUT 指定重启前停止容器的超时（默认为 10 秒）。 rm删除所有（停止状态的）服务容器。推荐先执行 docker-compose stop 命令来停止容器 格式为 docker-compose rm [options] [SERVICE…] 选项： - -f, --force 强制直接删除，包括非停止状态的容器。一般尽量不要使用该选项。 - -v 删除容器所挂载的数据卷。 run在指定服务上执行一个命令 格式为 docker-compose run [options] [-p PORT…] [-e KEY=VAL…] SERVICE [COMMAND] [ARGS…] eg:12docker-compose run ubuntu ping docker.com将会启动一个 ubuntu 服务容器，并执行 ping docker.com 命令 默认情况下，如果存在关联，则所有关联的服务将会自动被启动，除非这些服务已经在运行中。该命令类似启动容器后运行指定的命令，相关卷、链接等等都将会按照配置自动创建。 两个不同点： - 给定命令将会覆盖原有的自动运行命令； - 不会自动创建端口，以避免冲突。 如果不希望自动启动关联的容器，可以使用 –no-deps 选项，将不会启动 web 容器所关联的其它容器。 选项： - -d 后台运行容器。 - --name NAME 为容器指定一个名字。 - --entrypoint CMD 覆盖默认的容器启动指令。 - -e KEY=VAL 设置环境变量值，可多次使用选项来设置多个环境变量。 - -u, --user=&quot;&quot; 指定运行容器的用户名或者 uid。 - --no-deps 不自动启动关联的服务容器。 - --rm 运行命令后自动删除容器，d 模式下将忽略。 - -p, --publish=[] 映射容器端口到本地主机。 - --service-ports 配置服务端口并映射到本地主机。 - -T 不分配伪 tty，意味着依赖 tty 的指令将无法运行。 scale设置指定服务运行的容器个数，通过 service=num 的参数来设置数量。 格式为 docker-compose scale [options] [SERVICE=NUM…] 1234docker-compose scale web=3 db=2将启动 3 个容器运行 web 服务，2 个容器运行 db 服务。一般的，当指定数目多于该服务当前实际运行容器，将新创建并启动容器；反之，将停止容器。 选项： - -t, --timeout TIMEOUT 停止容器时候的超时（默认为 10 秒）。 start启动已经存在的服务容器 格式为 docker-compose start [SERVICE…] stop停止已经处于运行状态的容器，但不删除它。通过 docker-compose start 可以再次启动这些容器 格式为 docker-compose stop [options] [SERVICE…] 选项： - -t, --timeout TIMEOUT 停止容器时候的超时（默认为 10 秒）。 top查看各个服务容器内运行的进程。 unpause恢复处于暂停状态中的服务 格式为 docker-compose unpause [SERVICE…] up该命令十分强大，它将尝试自动完成包括构建镜像，（重新）创建服务，启动服务，并关联服务相关容器的一系列操作。 格式为 docker-compose up [options] [SERVICE…] 默认情况，如果服务容器已经存在，docker-compose up 将会尝试停止容器，然后重新创建（保持使用 volumes-from 挂载的卷），以保证新启动的服务匹配 docker-compose.yml 文件的最新内容。如果用户不希望容器被停止并重新创建，可以使用 docker-compose up –no-recreate。这样将只会启动处于停止状态的容器，而忽略已经运行的服务。如果用户只想重新部署某个服务，可以使用 docker-compose up –no-deps -d &lt;SERVICE_NAME&gt; 来重新创建服务并后台停止旧服务，启动新服务，并不会影响到其所依赖的服务。 选项： - -d 在后台运行服务容器。 - --no-color 不使用颜色来区分不同的服务的控制台输出。 - --no-deps 不启动服务所链接的容器。 - --force-recreate 强制重新创建容器，不能与 --no-recreate 同时使用。 - --no-recreate 如果容器已经存在了，则不重新创建，不能与 --force-recreate 同时使用。 - --no-build 不自动构建缺失的服务镜像。 - -t, --timeout TIMEOUT 停止容器时候的超时（默认为 10 秒）。]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dockerfile命令详解]]></title>
    <url>%2F2018%2F06%2F08%2Fdockerfile-command%2F</url>
    <content type="text"><![CDATA[Dockerfile是什么？简单说就是：镜像的定制 Docker 镜像是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。镜像不包含任何动态数据，其内容在构建之后也不会被改变。镜像的定制实际上就是定制每一层所添加的配置、文件。如果我们可以把每一层修改、安装、构建、操作的命令都写入一个脚本，用这个脚本来构建、定制镜像，那么之前提及的无法重复的问题、镜像构建透明性的问题、体积的问题就都会解决。这个脚本就是 Dockerfile。 为什么用Dockerfile？Dockerfile其实是用于微服务化项目中镜像内容的处理方法。用来定义镜像、依赖镜像来运行容器。使用Dockerfile非常容易的定义镜像内的内容。 Dockerfile 是一个文本文件，其内包含了一条条的指令(Instruction)，每一条指令构建一层，因此每一条指令的内容，就是描述该层应当如何构建。有了 Dockerfile，当我们需要定制自己额外的需求时，只需在 Dockerfile 上添加或者修改指令，重新生成 image 即可，省去了敲命令的麻烦。 换言之：我们可以通过一个简单的文件去创建镜像，启动容器等等的一系列脚本的动作。更方便的使我们部署项目 Dcokerfile文件格式1234567891011121314151617181920212223## Dockerfile文件格式# This dockerfile uses the ubuntu image# VERSION 2 - EDITION 1# Author: docker_user# Command format: Instruction [arguments / command] ..# 1、第一行必须指定 基础镜像信息FROM ubuntups: 除了选择现有镜像为基础镜像外，Docker 还存在一个特殊的镜像，名为 scratch。这个镜像是虚拟的概念，并不实际存在，它表示一个空白的镜像FROM scratch# 2、维护者信息MAINTAINER docker_user docker_user@email.com# 3、镜像操作指令RUN echo &quot;deb http://archive.ubuntu.com/ubuntu/ raring main universe&quot; &gt;&gt; /etc/apt/sources.listRUN apt-get update &amp;&amp; apt-get install -y nginxRUN echo &quot;\ndaemon off;&quot; &gt;&gt; /etc/nginx/nginx.conf# 4、容器启动执行指令CMD /usr/sbin/nginx Dcokerfile指令详解FROM:指定基础镜像FROM 指令用于指定其后构建新镜像所使用的基础镜像。FROM 指令必是 Dockerfile 文件中的首条命令，启动构建流程后，Docker 将会基于该镜像构建新镜像，FROM 后的命令也会基于这个基础镜像。 FROM语法格式为： 12345FROM &lt;image&gt;或者FROM &lt;image&gt;:&lt;tag&gt;或者FROM &lt;image&gt;:&lt;digest&gt; 通过 FROM 指定的镜像，可以是任何有效的基础镜像。FROM 有以下限制： FROM 必须 是 Dockerfile 中第一条非注释命令 在一个 Dockerfile 文件中创建多个镜像时，FROM 可以多次出现。只需在每个新命令 FROM 之前，记录提交(run)上次的镜像 ID。 tag 或 digest 是可选的，如果不使用这两个值时，会使用 latest 版本的基础镜像 RUN:执行命令在镜像的构建过程中执行特定的命令，并生成一个中间镜像。格式: 1234#shell格式(主要还是用shell方便)RUN &lt;command&gt;#exec格式RUN [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;] RUN 命令将在当前 image 中执行任意合法命令并提交执行结果。命令执行提交后，就会自动执行 Dockerfile 中的下一个指令。 层级 RUN 指令和生成提交是符合 Docker 核心理念的做法。它允许像版本控制那样，在任意一个点，对 image 镜像进行定制化构建。 RUN 指令创建的中间镜像会被缓存，并会在下次构建中使用。如果不想使用这些缓存镜像，可以在构建时指定 –no-cache 参数，如：docker build –no-cache。 COPY:复制文件格式： 123456789COPY &lt;源路径&gt;... &lt;目标路径&gt;COPY [&quot;&lt;源路径1&gt;&quot;,... &quot;&lt;目标路径&gt;&quot;]使用通配符，其通配符规则要满足 Go 的 filepath.Match 规则COPY hom* /mydir/COPY hom?.txt /mydir/eg:COPY my.cnf /etc/my.cnf ADD:更高级的复制文件ADD 指令和 COPY 的格式和性质基本一致。但是在 COPY 基础上增加了一些功能。比如&lt;源路径&gt;可以是一个 URL，这种情况下，Docker 引擎会试图去下载这个链接的文件放到&lt;目标路径&gt;去。 在构建镜像时，复制上下文中的文件到镜像内，格式： 12ADD &lt;源路径&gt;... &lt;目标路径&gt;ADD [&quot;&lt;源路径&gt;&quot;,... &quot;&lt;目标路径&gt;&quot;] 如果 docker 发现文件内容被改变，则接下来的指令都不会再使用缓存。关于复制文件时需要处理的/，基本跟正常的 copy 一致 ENV:设置环境变量格式有两种：12ENV &lt;key&gt; &lt;value&gt;ENV &lt;key1&gt;=&lt;value1&gt; &lt;key2&gt;=&lt;value2&gt;... 这个指令很简单，就是设置环境变量而已，无论是后面的其它指令，如 RUN，还是运行时的应用，都可以直接使用这里定义的环境变量。 12ENV VERSION=1.0 DEBUG=on \ NAME=&quot;Happy Feet&quot; 这个例子中演示了如何换行，以及对含有空格的值用双引号括起来的办法，这和 Shell 下的行为是一致的。 EXPOSE:设置监听端口1EXPOSE &lt;port&gt; [&lt;port&gt;...] EXPOSE 指令并不会让容器监听 host 的端口，如果需要，需要在 docker run 时使用 -p、-P 参数来发布容器端口到 host 的某个端口上。 VOLUME:定义匿名卷VOLUME用于创建挂载点，即向基于所构建镜像创始的容器添加卷： 1VOLUME [&quot;/data&quot;] 一个卷可以存在于一个或多个容器的指定目录，该目录可以绕过联合文件系统，并具有以下功能： 卷可以容器间共享和重用 容器并不一定要和其它容器共享卷 修改卷后会立即生效 对卷的修改不会对镜像产生影响 卷会一直存在，直到没有任何容器在使用它 VOLUME 让我们可以将源代码、数据或其它内容添加到镜像中，而又不并提交到镜像中，并使我们可以多个容器间共享这些内容。 WORKDIR:指定工作目录WORKDIR用于在容器内设置一个工作目录： 1WORKDIR /path/to/workdir 通过WORKDIR设置工作目录后，Dockerfile 中其后的命令 RUN、CMD、ENTRYPOINT、ADD、COPY 等命令都会在该目录下执行。 如，使用WORKDIR设置工作目录： 1234WORKDIR /aWORKDIR bWORKDIR cRUN pwd 在以上示例中，pwd 最终将会在 /a/b/c 目录中执行。在使用 docker run 运行容器时，可以通过-w参数覆盖构建时所设置的工作目录。 USER:指定当前用户USER 用于指定运行镜像所使用的用户： 1USER daemon 使用USER指定用户时，可以使用用户名、UID 或 GID，或是两者的组合。以下都是合法的指定试： 123456USER userUSER user:groupUSER uidUSER uid:gidUSER user:gidUSER uid:group 使用USER指定用户后，Dockerfile 中其后的命令 RUN、CMD、ENTRYPOINT 都将使用该用户。镜像构建完成后，通过 docker run 运行容器时，可以通过 -u 参数来覆盖所指定的用户。 CMD:指定在容器启动时所要执行的命令有以下三种格式： 123CMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;]CMD [&quot;param1&quot;,&quot;param2&quot;]CMD command param1 param2(shell) 省略可执行文件的 exec 格式，这种写法使 CMD 中的参数当做 ENTRYPOINT 的默认参数，此时 ENTRYPOINT 也应该是 exec 格式，具体与 ENTRYPOINT 的组合使用，参考 ENTRYPOINT。 注意与 RUN 指令的区别：RUN 在构建的时候执行，并生成一个新的镜像，CMD 在容器运行的时候执行，在构建时不进行任何操作。 ENTRYPOINTENTRYPOINT 用于给容器配置一个可执行程序。也就是说，每次使用镜像创建容器时，通过 ENTRYPOINT 指定的程序都会被设置为默认程序。ENTRYPOINT 有以下两种形式： 12ENTRYPOINT [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;]ENTRYPOINT command param1 param2 ENTRYPOINT 与 CMD 非常类似，不同的是通过docker run执行的命令不会覆盖 ENTRYPOINT，而docker run命令中指定的任何参数，都会被当做参数再次传递给 ENTRYPOINT。Dockerfile 中只允许有一个 ENTRYPOINT 命令，多指定时会覆盖前面的设置，而只执行最后的 ENTRYPOINT 指令。 docker run运行容器时指定的参数都会被传递给 ENTRYPOINT ，且会覆盖 CMD 命令指定的参数。如，执行docker run -d时，-d 参数将被传递给入口点。 也可以通过docker run –entrypoint重写 ENTRYPOINT 入口点。如：可以像下面这样指定一个容器执行程序： 1ENTRYPOINT [&quot;/usr/bin/nginx&quot;] 完整构建代码： 123456789# Version: 0.0.3FROM ubuntu:16.04MAINTAINER 何民三 &quot;cn.liuht@gmail.com&quot;RUN apt-get updateRUN apt-get install -y nginxRUN echo &apos;Hello World, 我是个容器&apos; \ &gt; /var/www/html/index.htmlENTRYPOINT [&quot;/usr/sbin/nginx&quot;]EXPOSE 80 使用docker build构建镜像，并将镜像指定为 itbilu/test： 1docker build -t=&quot;itbilu/test&quot; . ---后面的路径.别忘了 构建完成后，使用itbilu/test启动一个容器： 1docker run -i -t itbilu/test -g &quot;daemon off;&quot; 在运行容器时，我们使用了 -g “daemon off;”，这个参数将会被传递给 ENTRYPOINT，最终在容器中执行的命令为 /usr/sbin/nginx -g “daemon off;” LABELLABEL用于为镜像添加元数据，元数以键值对的形式指定： 1LABEL &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; ... 使用LABEL指定元数据时，一条LABEL指定可以指定一或多条元数据，指定多条元数据时不同元数据之间通过空格分隔。推荐将所有的元数据通过一条LABEL指令指定，以免生成过多的中间镜像。 如，通过LABEL指定一些元数据： 1LABEL version=&quot;1.0&quot; description=&quot;这是一个Web服务器&quot; by=&quot;IT笔录&quot; 指定后可以通过docker inspect查看： 123456docker inspect itbilu/test&quot;Labels&quot;: &#123; &quot;version&quot;: &quot;1.0&quot;, &quot;description&quot;: &quot;这是一个Web服务器&quot;, &quot;by&quot;: &quot;IT笔录&quot;&#125;, ARGARG用于指定传递给构建运行时的变量： 1ARG &lt;name&gt;[=&lt;default value&gt;] 如，通过ARG指定两个变量： 12ARG siteARG build_user=IT笔录 以上我们指定了 site 和 build_user 两个变量，其中 build_user 指定了默认值。在使用 docker build 构建镜像时，可以通过 –build-arg = 参数来指定或重设置这些变量的值。 1docker build --build-arg site=itiblu.com -t itbilu/test . 这样我们构建了 itbilu/test 镜像，其中site会被设置为 itbilu.com，由于没有指定 build_user，其值将是默认值 IT 笔录。 ONBUILDONBUILD用于设置镜像触发器： 1ONBUILD [INSTRUCTION] 当所构建的镜像被用做其它镜像的基础镜像，该镜像中的触发器将会被钥触发。 如，当镜像被使用时，可能需要做一些处理： 1234[...]ONBUILD ADD . /app/srcONBUILD RUN /usr/local/bin/python-build --dir /app/src[...] ps:因为在实际项目是依赖镜像的情况还是蛮多的，所以这个也会经常用到 STOPSIGNALSTOPSIGNAL用于设置停止容器所要发送的系统调用信号： 1STOPSIGNAL signal 所使用的信号必须是内核系统调用表中的合法的值，如：SIGKILL。 SHELLSHELL用于设置执行命令（shell式）所使用的的默认 shell 类型： 1SHELL [&quot;executable&quot;, &quot;parameters&quot;] SHELL在Windows环境下比较有用，Windows 下通常会有 cmd 和 powershell 两种 shell，可能还会有 sh。这时就可以通过 SHELL 来指定所使用的 shell 类型： 123456789101112131415FROM microsoft/windowsservercore# Executed as cmd /S /C echo defaultRUN echo default# Executed as cmd /S /C powershell -command Write-Host defaultRUN powershell -command Write-Host default# Executed as powershell -command Write-Host helloSHELL [&quot;powershell&quot;, &quot;-command&quot;]RUN Write-Host hello# Executed as cmd /S /C echo helloSHELL [&quot;cmd&quot;, &quot;/S&quot;&quot;, &quot;/C&quot;]RUN echo hello Dockerfile示例构建Nginx运行环境123456789101112131415161718192021222324252627282930313233343536373839404142# 指定基础镜像FROM sameersbn/ubuntu:14.04.20161014# 维护者信息MAINTAINER sameer@damagehead.com# 设置环境ENV RTMP_VERSION=1.1.10 \ NPS_VERSION=1.11.33.4 \ LIBAV_VERSION=11.8 \ NGINX_VERSION=1.10.1 \ NGINX_USER=www-data \ NGINX_SITECONF_DIR=/etc/nginx/sites-enabled \ NGINX_LOG_DIR=/var/log/nginx \ NGINX_TEMP_DIR=/var/lib/nginx \ NGINX_SETUP_DIR=/var/cache/nginx# 设置构建时变量，镜像建立完成后就失效ARG BUILD_LIBAV=falseARG WITH_DEBUG=falseARG WITH_PAGESPEED=trueARG WITH_RTMP=true# 复制本地文件到容器目录中COPY setup/ $&#123;NGINX_SETUP_DIR&#125;/RUN bash $&#123;NGINX_SETUP_DIR&#125;/install.sh# 复制本地配置文件到容器目录中COPY nginx.conf /etc/nginx/nginx.confCOPY entrypoint.sh /sbin/entrypoint.sh# 运行指令RUN chmod 755 /sbin/entrypoint.sh# 允许指定的端口EXPOSE 80/tcp 443/tcp 1935/tcp# 指定网站目录挂载点VOLUME [&quot;$&#123;NGINX_SITECONF_DIR&#125;&quot;]ENTRYPOINT [&quot;/sbin/entrypoint.sh&quot;]CMD [&quot;/usr/sbin/nginx&quot;] 构建tomcat 环境12345678910111213141516171819202122232425262728293031323334353637383940414243# 指定基于的基础镜像FROM ubuntu:13.10# 维护者信息MAINTAINER zhangjiayang &quot;zhangjiayang@sczq.com.cn&quot;# 镜像的指令操作# 获取APT更新的资源列表RUN echo &quot;deb http://archive.ubuntu.com/ubuntu precise main universe&quot;&gt; /etc/apt/sources.list# 更新软件RUN apt-get update# Install curlRUN apt-get -y install curl# Install JDK 7RUN cd /tmp &amp;&amp; curl -L &apos;http://download.oracle.com/otn-pub/java/jdk/7u65-b17/jdk-7u65-linux-x64.tar.gz&apos; -H &apos;Cookie: oraclelicense=accept-securebackup-cookie; gpw_e24=Dockerfile&apos; | tar -xzRUN mkdir -p /usr/lib/jvmRUN mv /tmp/jdk1.7.0_65/ /usr/lib/jvm/java-7-oracle/# Set Oracle JDK 7 as default JavaRUN update-alternatives --install /usr/bin/java java /usr/lib/jvm/java-7-oracle/bin/java 300RUN update-alternatives --install /usr/bin/javac javac /usr/lib/jvm/java-7-oracle/bin/javac 300# 设置系统环境ENV JAVA_HOME /usr/lib/jvm/java-7-oracle/# Install tomcat7RUN cd /tmp &amp;&amp; curl -L &apos;http://archive.apache.org/dist/tomcat/tomcat-7/v7.0.8/bin/apache-tomcat-7.0.8.tar.gz&apos; | tar -xzRUN mv /tmp/apache-tomcat-7.0.8/ /opt/tomcat7/ENV CATALINA_HOME /opt/tomcat7ENV PATH $PATH:$CATALINA_HOME/bin# 复件tomcat7.sh到容器中的目录ADD tomcat7.sh /etc/init.d/tomcat7RUN chmod 755 /etc/init.d/tomcat7# Expose ports. 指定暴露的端口EXPOSE 8080# Define default command.ENTRYPOINT service tomcat7 start &amp;&amp; tail -f /opt/tomcat7/logs/catalina.out tomcat7.sh命令文件 12345678910111213141516export JAVA_HOME=/usr/lib/jvm/java-7-oracle/export TOMCAT_HOME=/opt/tomcat7case $1 instart) sh $TOMCAT_HOME/bin/startup.sh;;stop) sh $TOMCAT_HOME/bin/shutdown.sh;;restart) sh $TOMCAT_HOME/bin/shutdown.sh sh $TOMCAT_HOME/bin/startup.sh;;esacexit 0 原则与建议 容器轻量化。从镜像中产生的容器应该尽量轻量化，能在足够短的时间内停止、销毁、重新生成并替换原来的容器。 使用 .gitignore。在大部分情况下，Dockerfile 会和构建所需的文件放在同一个目录中，为了提高构建的性能，应该使用 .gitignore 来过滤掉不需要的文件和目录。 为了减少镜像的大小，减少依赖，仅安装需要的软件包。 一个容器只做一件事。解耦复杂的应用，分成多个容器，而不是所有东西都放在一个容器内运行。如一个 Python Web 应用，可能需要 Server、DB、Cache、MQ、Log 等几个容器。一个更加极端的说法：One process per container。 减少镜像的图层。不要多个 Label、ENV 等标签。 对续行的参数按照字母表排序，特别是使用apt-get install -y安装包的时候。 使用构建缓存。如果不想使用缓存，可以在构建的时候使用参数–no-cache=true来强制重新生成中间镜像。]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker入门命令]]></title>
    <url>%2F2018%2F06%2F07%2Fdocker-command%2F</url>
    <content type="text"><![CDATA[Docker是这间博客的第一个系列，有很多内容都引用到了各个大神的内容。我会在这个系列发布的某一个时间点单独发表文章针对各个大神的感谢以及博文出处，在此专题系列的各个文章就不再赘述引用了。希望大神们能够理解。 docker 用于获取容器/镜像的元数据 1docker inspect 查看当前系统Docker信息: 1docker info 查看当前容器使用了多少资源: 1docker stats &lt;containerID&gt; image 查找Docker Hub上的nginx镜像 1docker search [image_name] 拉取docker镜像并启动 123456789101112131415161718docker run [OPTIONS] IMAGE [COMMAND] [ARG...]options:- -a stdin: 指定标准输入输出内容类型，可选 STDIN/STDOUT/STDERR 三项；- -d: 后台运行容器，并返回容器 ID；- -i: 以交互模式运行容器，通常与 -t 同时使用；- -t: 为容器重新分配一个伪输入终端，通常与 -i 同时使用；- --name=&quot;nginx-lb&quot;: 为容器指定一个名称；- --dns 8.8.8.8: 指定容器使用的 DNS 服务器，默认和宿主一致；- --dns-search example.com: 指定容器 DNS 搜索域名，默认和宿主一致；- -h &quot;mars&quot;: 指定容器的 hostname；- -e username=&quot;ritchie&quot;: 设置环境变量；- --env-file=[]: 从指定文件读入环境变量；- --cpuset=&quot;0-2&quot; or --cpuset=&quot;0,1,2&quot;: 绑定容器到指定 CPU 运行；- -m : 设置容器使用内存最大值；- --net=&quot;bridge&quot;: 指定容器的网络连接类型，支持 bridge/host/none/container: 四种类型；- --link=[]: 添加链接到另一个容器；- --expose=[]: 开放一个端口或一组端口； 查看宿主机上的镜像，Docker镜像保存在/var/lib/docker目录下: 123456789docker images或者docker image list或者docker image ls 创建镜像文件 12345$ docker image build -t [image_name]或者$ docker image build -t [image_name]:[tag] 删除镜像 1docker rmi docker.io/tomcat:7.0.77-jre7 或者 docker rmi [image_id] container 生成容器 12345$ docker container run -p [本机端口号]:[容器端口号] -it [image_name] /bin/bash或者$ docker container run -p 8[本机端口号]:[容器端口号] -it [image_name]:[tag] /bin/bash 123- -p参数：容器的 3000 端口映射到本机的 8000 端口。- -it参数：容器的 Shell 映射到当前的 Shell，然后你在本机窗口输入的命令，就会传入容器。- /bin/bash：容器启动以后，内部第一个执行的命令。这里是启动 Bash，保证用户可以使用 Shell。 查看当前有哪些容器正在运行 1docker ps 查看所有容器 1docker ps -a 终止容器运行: 1docker container kill [containerID] 启动、停止、重启容器命令： 12345docker run --name [自己定义的容器名称] -d -p [本机端口号]:[容器端口号] [image_name]:[tag]docker start [container_name]/[container_id]docker stop [container_name]/[container_id]docker restart [container_name]/[container_id] 后台启动一个容器后，如果想进入到这个容器，可以使用attach命令： 123456789docker attach [container_name]/[container_id]或者docker container exec -it [containerID] /bin/bash （进入一个正在运行的 docker 容器。如果docker run命令运行容器的时候，没有使用-it参数，就要用这个命令进入容器。一旦进入了容器，就可以在容器的 Shell 执行命令了。）或者docker exec -it [自己命名的容器名称] bash 删除容器的命令： 123docker rm [container_name]/[container_id]-v : 删除容器的同时，删除数据卷 删除所有停止的容器： 1docker rm $(docker ps -a -q) 在容器终止运行后自动删除容器文件: 1docker container run --rm -p 8000:3000 -it koa-demo /bin/bash 从正在运行的 Docker 容器里面，将文件拷贝到本机： 1docker container cp [containID]:[/path/to/file] push image123456781、 docker login2、docker image tag [imageName] [username]/[repository]:[tag] docker image tag koa-demos:0.0.1 ruanyf/koa-demos:0.0.13、 docker image build -t [username]/[repository]:[tag]4、docker image push [username]/[repository]:[tag]]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
</search>
